{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12379846,"sourceType":"datasetVersion","datasetId":7806066},{"sourceId":12380530,"sourceType":"datasetVersion","datasetId":7806526},{"sourceId":12381624,"sourceType":"datasetVersion","datasetId":7807278},{"sourceId":12381627,"sourceType":"datasetVersion","datasetId":7807281}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup Environment","metadata":{}},{"cell_type":"code","source":"!pip install -q torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:43:55.726618Z","iopub.execute_input":"2025-07-05T15:43:55.726903Z","iopub.status.idle":"2025-07-05T15:44:01.455227Z","shell.execute_reply.started":"2025-07-05T15:43:55.726885Z","shell.execute_reply":"2025-07-05T15:44:01.454536Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import Module, Embedding, Linear\nfrom torch_geometric.data import Data, Dataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tqdm import tqdm\nimport random\nimport time\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:01.456190Z","iopub.execute_input":"2025-07-05T15:44:01.456455Z","iopub.status.idle":"2025-07-05T15:44:12.028129Z","shell.execute_reply.started":"2025-07-05T15:44:01.456430Z","shell.execute_reply":"2025-07-05T15:44:12.027388Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"torch.manual_seed(42)\ntorch.cuda.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:12.030242Z","iopub.execute_input":"2025-07-05T15:44:12.030585Z","iopub.status.idle":"2025-07-05T15:44:12.039267Z","shell.execute_reply.started":"2025-07-05T15:44:12.030568Z","shell.execute_reply":"2025-07-05T15:44:12.038734Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class PrecomputedGraphDataset(Dataset):\n    def __init__(self, root_dir, graph_file, vocab_file, transform=None, pre_transform=None):\n        self.root_dir = root_dir\n        \n        # Tải dữ liệu đồ thị và từ điển từ các file JSON\n        with open(graph_file, 'r') as f:\n            self.graph_data_dict = json.load(f)\n        with open(vocab_file, 'r') as f:\n            self.vocabdict = json.load(f)\n            \n        self.all_paths = list(self.graph_data_dict.keys())\n        \n        # Xác định nhãn dựa trên đường dẫn file\n        self.labels = []\n        valid_paths = []\n        for path in self.all_paths:\n            # Chuẩn hóa đường dẫn để hoạt động trên mọi HĐH\n            normalized_path = path.replace('\\\\', '/')\n            if '/smelly/' in normalized_path:\n                self.labels.append(1)\n                valid_paths.append(path)\n            elif '/non-smelly/' in normalized_path:\n                self.labels.append(0)\n                valid_paths.append(path)\n        \n        # Chỉ giữ lại các đường dẫn có nhãn hợp lệ\n        self.all_paths = valid_paths\n\n        super(PrecomputedGraphDataset, self).__init__(root_dir, transform, pre_transform)\n        \n    def len(self):\n        return len(self.all_paths)\n\n    def get(self, idx):\n        # Lấy đường dẫn và nhãn tương ứng với chỉ số\n        path = self.all_paths[idx]\n        label = self.labels[idx]\n        \n        # Lấy dữ liệu đồ thị đã được tính toán trước từ dictionary\n        graph_info = self.graph_data_dict[path]\n        \n        # Giải nén dữ liệu\n        graph_tensors, astlength = graph_info\n        x_list, edge_index_list, edge_attr_list = graph_tensors\n        \n        # Chuyển đổi list thành tensor của PyTorch\n        x = torch.tensor(x_list, dtype=torch.long)\n        edge_index = torch.tensor(edge_index_list, dtype=torch.long)\n        edge_attr = torch.tensor(edge_attr_list, dtype=torch.long)\n        \n        # Kiểm tra và sửa lỗi shape nếu cần\n        if edge_index.dim() > 1 and edge_index.size(0) != 2 and edge_index.size(1) == 2:\n            edge_index = edge_index.t() # Chuyển vị nếu shape là [num_edges, 2]\n\n        # Tạo đối tượng Data của PyTorch Geometric\n        data = Data(\n            x=x,\n            edge_index=edge_index,\n            edge_type=edge_attr.squeeze(-1), # RGCNConv yêu cầu edge_type là 1D tensor\n            y=torch.tensor([label], dtype=torch.float)\n        )\n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:12.040074Z","iopub.execute_input":"2025-07-05T15:44:12.040574Z","iopub.status.idle":"2025-07-05T15:44:12.058815Z","shell.execute_reply.started":"2025-07-05T15:44:12.040546Z","shell.execute_reply":"2025-07-05T15:44:12.058233Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class RGCNCodeSmellClassifier(Module):\n    def __init__(self, vocab_size, num_relations, embedding_dim=256, gcn_hidden_dim=256, linear_hidden_dim=128):\n        super(RGCNCodeSmellClassifier, self).__init__()\n        self.embedding = Embedding(vocab_size, embedding_dim)\n        self.conv1 = RGCNConv(embedding_dim, gcn_hidden_dim, num_relations)\n        self.conv2 = RGCNConv(gcn_hidden_dim, gcn_hidden_dim, num_relations)\n        self.conv3 = RGCNConv(gcn_hidden_dim, gcn_hidden_dim, num_relations)\n        self.conv4 = RGCNConv(gcn_hidden_dim, gcn_hidden_dim, num_relations)\n        self.conv5 = RGCNConv(gcn_hidden_dim, gcn_hidden_dim, num_relations)\n        self.fc1 = Linear(gcn_hidden_dim, linear_hidden_dim)\n        self.fc2 = Linear(linear_hidden_dim, 1)\n\n    def forward(self, data):\n        x, edge_index, edge_type, batch = data.x, data.edge_index, data.edge_type, data.batch\n        x = self.embedding(x.squeeze(-1))\n        x = F.relu(self.conv1(x, edge_index, edge_type))\n        x = F.relu(self.conv2(x, edge_index, edge_type))\n        x = F.relu(self.conv3(x, edge_index, edge_type))\n        x = F.relu(self.conv4(x, edge_index, edge_type))\n        x = F.relu(self.conv5(x, edge_index, edge_type))\n        graph_embedding = global_mean_pool(x, batch)\n        x = F.relu(self.fc1(graph_embedding))\n        x = F.dropout(x, p=0.5, training=self.training)\n        out = self.fc2(x)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:12.059746Z","iopub.execute_input":"2025-07-05T15:44:12.060433Z","iopub.status.idle":"2025-07-05T15:44:12.075822Z","shell.execute_reply.started":"2025-07-05T15:44:12.060414Z","shell.execute_reply":"2025-07-05T15:44:12.075141Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Train & Evaluation","metadata":{}},{"cell_type":"code","source":"def train(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    dataset_size = len(loader.dataset)\n    for data in tqdm(loader, desc=\"Training\"):\n        data = data.to(device)\n        optimizer.zero_grad()\n        out = model(data)\n        loss = criterion(out, data.y.view_as(out))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * data.num_graphs\n    return total_loss / dataset_size\n\ndef evaluate(model, loader, device):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for data in tqdm(loader, desc=\"Evaluating\"):\n            data = data.to(device)\n            out = model(data)\n            preds = (torch.sigmoid(out) > 0.5).cpu().numpy()\n            labels = data.y.cpu().numpy()\n            all_preds.extend(preds.flatten())\n            all_labels.extend(labels.flatten())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, zero_division=0)\n    recall = recall_score(all_labels, all_preds, zero_division=0)\n    f1 = f1_score(all_labels, all_preds, zero_division=0)\n    return accuracy, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:12.076569Z","iopub.execute_input":"2025-07-05T15:44:12.076800Z","iopub.status.idle":"2025-07-05T15:44:12.093544Z","shell.execute_reply.started":"2025-07-05T15:44:12.076776Z","shell.execute_reply":"2025-07-05T15:44:12.093075Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Train Loop","metadata":{}},{"cell_type":"code","source":"def main():\n    # --- Cấu hình ---\n    DATA_ROOT = \"/kaggle/input/sdwllm-code-smell-long-method\"\n    GRAPH_DATA_FILE = os.path.join(DATA_ROOT, \"graph.json\")\n    VOCAB_FILE = os.path.join(DATA_ROOT, \"vocabdict.json\")\n    \n    NUM_EPOCHS = 10\n    BATCH_SIZE = 32\n    # godclass 0.0005\n    # dataclass 0.0005\n    # featureenvy 0.0001\n    # longmethod 0.0005\n    LEARNING_RATE = 0.0005\n\n    # --- Tải từ điển và Dataset ---\n    print(\"Tải dữ liệu từ file JSON...\")\n    dataset = PrecomputedGraphDataset(root_dir=DATA_ROOT, graph_file=GRAPH_DATA_FILE, vocab_file=VOCAB_FILE)\n    \n    # --- Chia dữ liệu thành 3 tập: 70% train, 20% validation, 10% test ---\n    print(\"Chia dữ liệu thành các tập train, validation, và test...\")\n    indices = list(range(len(dataset)))\n    labels = np.array(dataset.labels)\n    \n    # Bước 1: Chia 70% train và 30% còn lại (dành cho validation và test)\n    train_indices, temp_indices, train_labels, temp_labels = train_test_split(\n        indices, labels, test_size=0.3, random_state=42, stratify=labels\n    )\n    # Bước 2: Chia 30% còn lại thành 20% validation và 10% test\n    # Tỷ lệ test trong tập temp là 10/30 = 1/3\n    valid_indices, test_indices, valid_labels, test_labels = train_test_split(\n        temp_indices, temp_labels, test_size=(1/3), random_state=42, stratify=temp_labels\n    )\n\n    print(f\"Tổng số mẫu: {len(dataset)}\")\n    print(f\"Số mẫu train: {len(train_indices)} (~{len(train_indices)/len(dataset)*100:.1f}%)\"\n          f\" -> Smelly(1): {np.sum(train_labels == 1)}, Non-smelly(0): {np.sum(train_labels == 0)}\")\n    print(f\"Số mẫu validation: {len(valid_indices)} (~{len(valid_indices)/len(dataset)*100:.1f}%)\"\n          f\" -> Smelly(1): {np.sum(valid_labels == 1)}, Non-smelly(0): {np.sum(valid_labels == 0)}\")\n    print(f\"Số mẫu test: {len(test_indices)} (~{len(test_indices)/len(dataset)*100:.1f}%)\"\n          f\" -> Smelly(1): {np.sum(test_labels == 1)}, Non-smelly(0): {np.sum(test_labels == 0)}\")\n\n    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n    valid_dataset = torch.utils.data.Subset(dataset, valid_indices)\n    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    # --- Khởi tạo mô hình, optimizer và loss ---\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Sử dụng thiết bị: {device}\")\n    \n    vocab_size = len(dataset.vocabdict)\n    # 9 loại cạnh, có forward/backward nên x2:\n    # Child/Parent, NextSib/PrevSib, NextToken/PrevToken, NextUse/PrevUse,\n    # CondTrue/Rev, CondFalse/Rev, WhileExec/WhileNext, ForExec/ForNext, NextStmt/PrevStmt\n    num_relations = 18\n\n    model = RGCNCodeSmellClassifier(vocab_size=vocab_size, num_relations=num_relations).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    \n    # Tính toán trọng số cho lớp thiểu số (positive class - smelly)\n    num_negatives = np.sum(train_labels == 0)\n    num_positives = np.sum(train_labels == 1)\n    \n    if num_positives > 0:\n        # godclass /2\n        # dataclass /2\n        # featureenvy *1\n        # longmethod /2\n        pos_weight_value = num_negatives / num_positives / 2\n        pos_weight = torch.tensor([pos_weight_value], dtype=torch.float).to(device)\n        print(f\"Áp dụng trọng số cho lớp Smelly (positive): {pos_weight.item():.2f}\")\n    else:\n        pos_weight = None # Không có mẫu positive trong tập train\n        print(\"Không tìm thấy mẫu Smelly trong tập train. Không áp dụng trọng số.\")\n\n    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\n    # --- Vòng lặp huấn luyện ---\n    print(\"Bắt đầu huấn luyện...\")\n    start_time = time.time()\n    for epoch in range(1, NUM_EPOCHS + 1):\n        train_loss = train(model, train_loader, optimizer, criterion, device)\n        \n        # Đánh giá trên tập validation sau mỗi epoch\n        val_accuracy, val_precision, val_recall, val_f1 = evaluate(model, valid_loader, device)\n        \n        print(f'Epoch: {epoch:02d}, Loss: {train_loss:.4f}, '\n              f'Val Acc: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, '\n              f'Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')\n    training_time = time.time() - start_time\n    mins, secs = divmod(training_time, 60)\n    \n    # --- Đánh giá cuối cùng trên tập test ---\n    print(\"\\nĐã huấn luyện xong. Đánh giá trên tập test cuối cùng...\")\n    test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n    \n    print(f'========== Final Test Results ==========')\n    print(f'Test Accuracy:  {test_accuracy:.4f}')\n    print(f'Test Precision: {test_precision:.4f}')\n    print(f'Test Recall:    {test_recall:.4f}')\n    print(f'Test F1-Score:  {test_f1:.4f}')\n    print(f'Training Time:  {round(mins)}m {round(secs)}s')\n    print(f'======================================')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:12.094452Z","iopub.execute_input":"2025-07-05T15:44:12.094739Z","iopub.status.idle":"2025-07-05T15:44:12.115366Z","shell.execute_reply.started":"2025-07-05T15:44:12.094721Z","shell.execute_reply":"2025-07-05T15:44:12.114667Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:44:12.116188Z","iopub.execute_input":"2025-07-05T15:44:12.116425Z","iopub.status.idle":"2025-07-05T15:44:57.162414Z","shell.execute_reply.started":"2025-07-05T15:44:12.116401Z","shell.execute_reply":"2025-07-05T15:44:57.161865Z"}},"outputs":[{"name":"stdout","text":"Tải dữ liệu từ file JSON...\nChia dữ liệu thành các tập train, validation, và test...\nTổng số mẫu: 2234\nSố mẫu train: 1563 (~70.0%) -> Smelly(1): 169, Non-smelly(0): 1394\nSố mẫu validation: 447 (~20.0%) -> Smelly(1): 49, Non-smelly(0): 398\nSố mẫu test: 224 (~10.0%) -> Smelly(1): 24, Non-smelly(0): 200\nSử dụng thiết bị: cuda\nÁp dụng trọng số cho lớp Smelly (positive): 4.12\nBắt đầu huấn luyện...\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:04<00:00, 10.79it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 20.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 01, Loss: 0.6142, Val Acc: 0.8814, Val Precision: 0.4773, Val Recall: 0.8571, Val F1: 0.6131\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.76it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 22.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 02, Loss: 0.3320, Val Acc: 0.8859, Val Precision: 0.4889, Val Recall: 0.8980, Val F1: 0.6331\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.89it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 23.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 03, Loss: 0.2704, Val Acc: 0.8993, Val Precision: 0.5286, Val Recall: 0.7551, Val F1: 0.6218\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.51it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 22.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 04, Loss: 0.1927, Val Acc: 0.9038, Val Precision: 0.5405, Val Recall: 0.8163, Val F1: 0.6504\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.88it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 22.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 05, Loss: 0.1590, Val Acc: 0.9239, Val Precision: 0.6271, Val Recall: 0.7551, Val F1: 0.6852\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.63it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 22.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 06, Loss: 0.0973, Val Acc: 0.9262, Val Precision: 0.7000, Val Recall: 0.5714, Val F1: 0.6292\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.81it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 22.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 07, Loss: 0.0719, Val Acc: 0.9239, Val Precision: 0.6316, Val Recall: 0.7347, Val F1: 0.6792\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.91it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 22.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 08, Loss: 0.0891, Val Acc: 0.9038, Val Precision: 0.5366, Val Recall: 0.8980, Val F1: 0.6718\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.80it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 23.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 09, Loss: 0.0583, Val Acc: 0.9038, Val Precision: 0.5417, Val Recall: 0.7959, Val F1: 0.6446\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 49/49 [00:03<00:00, 13.95it/s]\nEvaluating: 100%|██████████| 14/14 [00:00<00:00, 23.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10, Loss: 0.0493, Val Acc: 0.9105, Val Precision: 0.5652, Val Recall: 0.7959, Val F1: 0.6610\n\nĐã huấn luyện xong. Đánh giá trên tập test cuối cùng...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 7/7 [00:00<00:00, 23.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"========== Final Test Results ==========\nTest Accuracy:  0.9554\nTest Precision: 0.7188\nTest Recall:    0.9583\nTest F1-Score:  0.8214\nTraining Time:  0m 43s\n======================================\n","output_type":"stream"}],"execution_count":8}]}